{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23a776a-6c12-4689-9282-ff1074e9525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: Tensorflow\\workspace\\images\\collectedimages\n",
      "Created directory: Tensorflow\\workspace\\images\\collectedimages\\coercion\n",
      "Collecting images for coercion\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.70670cc5-3175-11ef-95ab-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.719c6618-3175-11ef-8b04-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.72d2bf96-3175-11ef-9b53-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.7409491e-3175-11ef-8438-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.753e264d-3175-11ef-a715-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.7671c8be-3175-11ef-8e27-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.77a4f65f-3175-11ef-9ced-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.78d9691e-3175-11ef-91ab-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.7a0c4e23-3175-11ef-b5b4-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.7b42906d-3175-11ef-8f89-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.7c77da41-3175-11ef-8960-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.7dacce09-3175-11ef-a537-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.7ee240f1-3175-11ef-b4f9-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.801ac332-3175-11ef-be64-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\coercion\\coercion.815072a0-3175-11ef-a6fa-c46516f8eaa9.jpg\n",
      "Created directory: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\n",
      "Collecting images for domestic violence\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.8895a3ca-3175-11ef-9842-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.89d042b1-3175-11ef-8619-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.8b035de4-3175-11ef-8444-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.8c36f4f0-3175-11ef-8755-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.8d6ccd47-3175-11ef-9b38-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.8ea05fe3-3175-11ef-8764-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.8fd506d4-3175-11ef-a899-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.910886ab-3175-11ef-be82-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.923c55de-3175-11ef-a321-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.936ffabf-3175-11ef-b62a-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.94a5e2e3-3175-11ef-a9cd-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.95d8c1f6-3175-11ef-8ded-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.970c5f7e-3175-11ef-9cb1-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.984005c5-3175-11ef-a032-c46516f8eaa9.jpg\n",
      "Saved image: Tensorflow\\workspace\\images\\collectedimages\\domestic violence\\domestic violence.99743ad9-3175-11ef-b2d3-c46516f8eaa9.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# Define the path where the images will be stored\n",
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')\n",
    "# Define the labels and the number of images to be collected per label\n",
    "labels = ['coercion', 'domestic violence']\n",
    "number_imgs = 15\n",
    "\n",
    "# Create the main directory if it doesn't exist\n",
    "if not os.path.exists(IMAGES_PATH):\n",
    "    os.makedirs(IMAGES_PATH)\n",
    "    print(f\"Created directory: {IMAGES_PATH}\")\n",
    "\n",
    "for label in labels:\n",
    "    # Create a subdirectory for each label\n",
    "    label_path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(label_path):\n",
    "        os.makedirs(label_path)\n",
    "        print(f\"Created directory: {label_path}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)  # Wait for 5 seconds before starting image collection\n",
    "    \n",
    "    for imgnum in range(number_imgs):\n",
    "        ret, frame = cap.read()  # Capture a frame\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image\")\n",
    "            continue\n",
    "        \n",
    "        # Create a unique name for the image\n",
    "        imagename = os.path.join(label_path, label + '.' + '{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imagename, frame)  # Save the captured frame to the specified path\n",
    "        print(f\"Saved image: {imagename}\")\n",
    "        cv2.imshow('frame', frame)  # Display the frame\n",
    "        \n",
    "        time.sleep(2)  # Wait for 2 seconds before capturing the next image\n",
    "        \n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()  # Release the webcam\n",
    "    cv2.destroyAllWindows()  # Close any OpenCV windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad29b2-a882-4c36-b675-eb3be6a4d658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
